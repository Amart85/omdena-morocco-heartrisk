{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd                                     # Data analysis and manipultion tool\nimport numpy as np                                      # Fundamental package for linear algebra and multidimensional arrays\nimport tensorflow as tf                                 # Deep Learning Tool\nimport os\nimport os.path\nimport fnmatch\nfrom pathlib import Path\nimport cv2                                              # Library for image processing\nfrom sklearn.model_selection import train_test_split    # For splitting the data into train and validation set\nfrom sklearn.metrics import f1_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras import datasets, layers, models, losses, Model, optimizers\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.initializers import RandomUniform\nimport datetime as dt\nfrom PIL import Image\nimport time\nimport glob\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-10T18:13:05.862745Z","iopub.execute_input":"2021-08-10T18:13:05.863137Z","iopub.status.idle":"2021-08-10T18:13:05.871007Z","shell.execute_reply.started":"2021-08-10T18:13:05.863099Z","shell.execute_reply":"2021-08-10T18:13:05.869893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ECG Image Dataset \nHere I load and read the data, then label each folder with its respective name:\n\n\n*   **MI**\n*   **HMI**\n*   **AbnHB**\n*   **Normal**\n\n\n## Task 0 : Loading & Reading the ECG Image Dataset\n## Task 1 : Cropping ECG Images &&  Background Removal\n## Task 2 : Extracting 12 Leads of ECG Signal Image\n## Task 3 : GLCM & Feature Extraction\n\n\n### AB","metadata":{}},{"cell_type":"markdown","source":"# Task 0","metadata":{}},{"cell_type":"code","source":"#print('Getting ECG Images with Covid19')\n#!wget \"https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/gwbz3fsgp8-1.zip\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!unzip gwbz3fsgp8-1.zip -d /kaggle/working/ECG_Covid/\n#print(\"Done Unzipping into /ECG_Covid/ folder\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Getting ECG Images')\n!wget \"https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/gwbz3fsgp8-2.zip\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip gwbz3fsgp8-2.zip -d /kaggle/working/ECG_IM/\nprint(\"Done Unzipping into /ECG_IM/ folder\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MI patients data\nECG_MI_dir_ = Path('./ECG_IM/ECG Images of Myocardial Infarction Patients (240x12=2880)')\n\n# Filepaths:\nECG_MI_filepaths = list(ECG_MI_dir_.glob(r'**/*.jpg'))\n\n# filename\nMI_fnames = []\nfor path, dirs, files in os.walk(os.path.abspath(r\"./ECG_IM/ECG Images of Myocardial Infarction Patients (240x12=2880)/\")):\n    for filename in fnmatch.filter(files, \"*.jpg\"):\n        #print(filename)\n        MI_fnames.append(filename)\n# Mapping the labels\nMI_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], ECG_MI_filepaths))\n# Paths & labels \nECG_MI_filepaths = pd.Series(ECG_MI_filepaths, name = 'filepath').astype(str)\nMI_fnames = pd.Series(MI_fnames, name='filename')\nMI_labels = pd.Series(MI_labels, name='label')\n\n# Concatenating...\nMI_df = pd.concat([MI_fnames,ECG_MI_filepaths, MI_labels], axis=1)\nMI_df['label'] = \"MI\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MI_df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Example of MI\nfigure = plt.figure(figsize=(20,10))\nx = plt.imread(MI_df[\"filepath\"][0])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(str('label: ')+MI_df[\"label\"][0]+str(' ,filename: ') +str(MI_df['filename'][0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# HMI patients data\nECG_HMI_dir_ = Path('./ECG_IM/ECG Images of Patient that have History of MI (172x12=2064)')\n\n#FilePath\nECG_HMI_filepaths = list(ECG_HMI_dir_.glob(r'**/*.jpg'))\n\n# filename\nHMI_fnames = []\nfor path, dirs, files in os.walk(os.path.abspath(r\"./ECG_IM/ECG Images of Patient that have History of MI (172x12=2064)/\")):\n    for filename in fnmatch.filter(files, \"*.jpg\"):\n        #print(filename)\n        HMI_fnames.append(filename)\n\n# Mapping the labels\nHMI_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], ECG_HMI_filepaths))\n\n# Filepath & labels\nECG_HMI_filepaths = pd.Series(ECG_HMI_filepaths, name = 'filepath').astype(str)\nHMI_fnames = pd.Series(HMI_fnames, name='filename')\nHMI_labels = pd.Series(HMI_labels, name='label')\n\n# Concatenating...\nHMI_df = pd.concat([HMI_fnames,ECG_HMI_filepaths, HMI_labels], axis=1)\nHMI_df['label'] = \"HMI\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Example of MI\nfigure = plt.figure(figsize=(20,10))\nx = plt.imread(HMI_df[\"filepath\"][0])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(str('label: ')+HMI_df[\"label\"][0]+str(' ,filename: ') +str(HMI_df['filename'][0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AbnHB patients data\nECG_AbnHB_dir_ = Path('./ECG_IM/ECG Images of Patient that have abnormal heartbeat (233x12=2796)')\n\n#Filepath\nECG_AbnHB_filepaths = list(ECG_AbnHB_dir_.glob(r'**/*.jpg'))\n\n# filename\nAbnHB_fnames = []\nfor path, dirs, files in os.walk(os.path.abspath(r\"./ECG_IM/ECG Images of Patient that have abnormal heartbeat (233x12=2796)/\")):\n    for filename in fnmatch.filter(files, \"*.jpg\"):\n        #print(filename)\n        AbnHB_fnames.append(filename)\n# Mapping the labels\nAbnHB_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], ECG_AbnHB_filepaths))\n\n# Filepaths & labels \nECG_AbnHB_filepaths = pd.Series(ECG_AbnHB_filepaths, name = 'filepath').astype(str)\nAbnHB_fnames = pd.Series(AbnHB_fnames, name='filename')\nAbnHB_labels = pd.Series(AbnHB_labels, name='label')\n\n# Concatenating...\nAbnHB_df = pd.concat([AbnHB_fnames,ECG_AbnHB_filepaths, AbnHB_labels], axis=1)\nAbnHB_df['label'] = \"ABNORMAL\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Example of MI\nfigure = plt.figure(figsize=(20,10))\nx = plt.imread(AbnHB_df[\"filepath\"][0])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(str('label: ')+AbnHB_df[\"label\"][0]+str(' ,filename: ') +str(AbnHB_df['filename'][0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AbnHB_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normal patients data\nECG_Normal_dir_ = Path('./ECG_IM/Normal Person ECG Images (284x12=3408)')\n#Filepath\nECG_Normal_filepaths = list(ECG_Normal_dir_.glob(r'**/*.jpg'))\n\n# filename\nNormal_fnames = []\nfor path, dirs, files in os.walk(os.path.abspath(r\"./ECG_IM/Normal Person ECG Images (284x12=3408)/\")):\n    for filename in fnmatch.filter(files, \"*.jpg\"):\n        #print(filename)\n        Normal_fnames.append(filename)\n        \n# Mapping the labels\nNormal_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], ECG_Normal_filepaths))\n# Paths & labels femalee eyes\nECG_Normal_filepaths = pd.Series(ECG_Normal_filepaths, name = 'filepath').astype(str)\nNormal_fnames = pd.Series(Normal_fnames, name='filename')\nNormal_labels = pd.Series(Normal_labels, name='label')\n\n# Concatenating...\nNormal_df = pd.concat([Normal_fnames,ECG_Normal_filepaths, Normal_labels], axis=1)\nNormal_df['label'] = \"NORMAL\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Example of MI\nfigure = plt.figure(figsize=(20,10))\nx = plt.imread(Normal_df[\"filepath\"][0])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(str('label: ')+Normal_df[\"label\"][0]+str(' ,filename: ') +str(Normal_df['filename'][0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 1:","metadata":{}},{"cell_type":"code","source":"def im_crop(image,left=71.5, top= 287.5, right=2102, bottom= 1228):\n    \"\"\" This function is used to crop the image and get just the ECG signals.\n      input: \n        image : the image (jpg,png,...Etc)\n        left: location in left of image\n        top: location in top of image\n        right: location in right of image\n        bottom: location in bottom of image\n\n        ######\n        # choices from paper: left=71.5, top= 287.5, right=2102, bottom= 1228\n        ######\n      output: \n        img_out: the cropped ECG image.\n  \"\"\"\n    img = Image.open(image)\n    img_out = img.crop((left, top, right, bottom))\n  \n\n    return img_out\n\n\n\ndef bg_remover(image,name):\n  \n    # The Image will be of type PIL.Image.Image , so we will convert it to np.asarray:\n    img = np.asarray(image)\n    \n    # convert to graky\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n    # threshold input image as mask\n    mask = cv2.threshold(gray, 250, 255, cv2.THRESH_BINARY)[1]\n\n    # negate mask\n    mask = 255 - mask\n\n    # apply morphology to remove isolated extraneous noise\n    # use borderconstant of black since foreground touches the edges\n    kernel = np.ones((3,3), np.uint8)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n\n    # anti-alias the mask -- blur then stretch\n    # blur alpha channel\n    mask = cv2.GaussianBlur(mask, (0,0), sigmaX=2, sigmaY=2, borderType = cv2.BORDER_DEFAULT)\n\n    # linear stretch so that 127.5 goes to 0, but 255 stays 255\n    mask = (2*(mask.astype(np.float32))-255.0).clip(0,255).astype(np.uint8)\n\n    # put mask into alpha channel\n    result = img.copy()\n    result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n    result[:, :, 3] = mask\n\n    # save resulting masked image\n    cv2.imwrite('/kaggle/working/outECG/'+ str(name), result)\n    #Image.fromarray(result).save('/kaggle/working/outECG/'+ str(name)+str('.png'))\n    result = Image.fromarray(result)\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rv /kaggle/working/outECG/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Output folder for the respective categories of ECG Images after Cropping & Background Removal\n!mkdir /kaggle/working/outECG/\n!mkdir /kaggle/working/outECG/MI_c_bg/\n!mkdir /kaggle/working/outECG/HMI_c_bg/\n!mkdir /kaggle/working/outECG/AbnHB_c_bg/\n!mkdir /kaggle/working/outECG/Normal_c_bg/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# MI images\nMI_c_bg= []\nfor i in range(0,MI_df.shape[0]):\n    MI_c_bg.append(bg_remover(im_crop(MI_df[\"filepath\"][i]),'MI_c_bg/' + str(MI_df[\"filename\"][i])))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# HMI images\nHMI_c_bg= []\nfor i in range(0,HMI_df.shape[0]):\n    HMI_c_bg.append(bg_remover(im_crop(HMI_df[\"filepath\"][i]),'HMI_c_bg/' + str(HMI_df[\"filename\"][i])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Normal images\nNormal_c_bg= []\nfor i in range(0,Normal_df.shape[0]):\n    Normal_c_bg.append(bg_remover(im_crop(Normal_df[\"filepath\"][i]), 'Normal_c_bg/' + str(Normal_df[\"filename\"][i])))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Abnormal HB images\nAbnHB_c_bg= []\nfor i in range(0,AbnHB_df.shape[0]):\n    AbnHB_c_bg.append(bg_remover(im_crop(AbnHB_df[\"filepath\"][i]),'AbnHB_c_bg/' + str(AbnHB_df[\"filename\"][i]) ))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Creating Dataframes from the croped images to use in next task **\n","metadata":{}},{"cell_type":"code","source":"# To use it for Segmenting 12 leads\nMI_c_bg_df = pd.DataFrame(MI_c_bg, columns=['PilImage'])\nMI_c_bg_df['filename']= MI_df[\"filename\"]\nMI_c_bg_df['filename'].replace({\"\\(\":\"_\",'\\).jpg':''}, regex=True,inplace=True)\nMI_c_bg_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To use it for Segmenting 12 leads\nHMI_c_bg_df = pd.DataFrame(HMI_c_bg, columns=['PilImage'])\nHMI_c_bg_df['filename']= HMI_df[\"filename\"]\nHMI_c_bg_df['filename'].replace({\"\\(\":\"_\",'\\).jpg':''}, regex=True,inplace=True)\nHMI_c_bg_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To use it for Segmenting 12 leads\nAbnHB_c_bg_df = pd.DataFrame(AbnHB_c_bg, columns=['PilImage'])\nAbnHB_c_bg_df['filename']= AbnHB_df[\"filename\"]\nAbnHB_c_bg_df['filename'].replace({\"\\(\":\"_\",'\\).jpg':''}, regex=True,inplace=True)\nAbnHB_c_bg_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To use it for Segmenting 12 leads\nNormal_c_bg_df = pd.DataFrame(Normal_c_bg, columns=['PilImage'])\nNormal_c_bg_df['filename']= Normal_df[\"filename\"]\nNormal_c_bg_df['filename'].replace({\"\\(\":\"_\",'\\).jpg':''}, regex=True,inplace=True)\nNormal_c_bg_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 2: ","metadata":{}},{"cell_type":"markdown","source":"* Crate folders for the 12 leads\n\n\n# Output folder for the respective categories of ECG Images after Cropping & Background Removal\n\n* !mkdir /kaggle/working/ECG_leads/\n\n\n* !mkdir -p /kaggle/working/ECG_leads/MI/{I,I_Neg,II,II_Neg,III,III_Neg,aVR,aVR_Neg,aVL,aVL_Neg,aVF,aVF_Neg,V1,V2,V3,V4,V5,V6}/\n\n* !mkdir -p /kaggle/working/ECG_leads/HMI/{I,I_Neg,II,II_Neg,III,III_Neg,aVR,aVR_Neg,aVL,aVL_Neg,aVF,aVF_Neg,V1,V2,V3,V4,V5,V6}/\n\n* !mkdir -p /kaggle/working/ECG_leads/AbnHB/{I,I_Neg,II,II_Neg,III,III_Neg,aVR,aVR_Neg,aVL,aVL_Neg,aVF,aVF_Neg,V1,V2,V3,V4,V5,V6}/\n\n* !mkdir -p /kaggle/working/ECG_leads/Normal/{I,I_Neg,II,II_Neg,III,III_Neg,aVR,aVR_Neg,aVL,aVL_Neg,aVF,aVF_Neg,V1,V2,V3,V4,V5,V6}/","metadata":{}},{"cell_type":"code","source":"!mkdir /kaggle/working/ECG_leads/\n!mkdir -p /kaggle/working/ECG_leads/MI/{I,I_Neg,II,II_Neg,III,III_Neg,aVR,aVR_Neg,aVL,aVL_Neg,aVF,aVF_Neg,V1,V2,V3,V4,V5,V6}/\n!mkdir -p /kaggle/working/ECG_leads/HMI/{I,I_Neg,II,II_Neg,III,III_Neg,aVR,aVR_Neg,aVL,aVL_Neg,aVF,aVF_Neg,V1,V2,V3,V4,V5,V6}/\n!mkdir -p /kaggle/working/ECG_leads/AbnHB/{I,I_Neg,II,II_Neg,III,III_Neg,aVR,aVR_Neg,aVL,aVL_Neg,aVF,aVF_Neg,V1,V2,V3,V4,V5,V6}/\n!mkdir -p /kaggle/working/ECG_leads/Normal/{I,I_Neg,II,II_Neg,III,III_Neg,aVR,aVR_Neg,aVL,aVL_Neg,aVF,aVF_Neg,V1,V2,V3,V4,V5,V6}/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Function to Extract the 12 Leads.\n\nI will try to Place each lead into its respective Repository, any Idea how to do it ?","metadata":{}},{"cell_type":"code","source":"def seg_save_12leads(image,folder,name, width= 315, height= 315):\n\n    # Segment 12 Leads of ECG Signal\n    I_img   = image.crop((120.5, 0.5, width + 120.5 , 0.5 + height)).convert('L') # Converting Images to Grayscale\n    II_img  = image.crop((120.5, 315.5, width + 120.5 , 315.5+ height)).convert('L')\n    III_img = image.crop((120.5, 630.5, width + 120.5 , 630.5+ height)).convert('L')\n    aVR_img = image.crop((672.5, 0.5, width + 672.5 , 0.5 + height)).convert('L')\n    aVL_img = image.crop((672.5, 315.5, width + 672.5 , 315.5+ height)).convert('L')\n    aVF_img = image.crop((672.5, 630.5, width + 672.5 , 630.5+ height)).convert('L')\n    V1_img  = image.crop((1133.5, 0.5, width + 1133.5 , 0.5+ height)).convert('L')\n    V2_img  = image.crop((1133.5, 315.5, width + 1133.5 , 315.5+ height)).convert('L')\n    V3_img  = image.crop((1133.5, 630.5, width + 1133.5 , 630.5+ height)).convert('L')\n    V4_img  = image.crop((1639.5, 0.5, width + 1639.5 , 0.5 + height)).convert('L')\n    V5_img  = image.crop((1639.5, 0.5, width + 1639.5 , 0.5+ height)).convert('L')\n    V6_img  = image.crop((1639.5, 630.5, width + 1639.5 , 630.5+ height)).convert('L')\n    \n    \n    # Negative leads I,II,III, aVR,aVL,aVF\n    \n    I_neg_img   = Image.fromarray(cv2.flip(np.asarray(I_img),0)) # Vertical Flip\n    II_neg_img  = Image.fromarray(cv2.flip(np.asarray(II_img),0)) # Vertical Flip\n    III_neg_img = Image.fromarray(cv2.flip(np.asarray(III_img),0)) # Vertical Flip\n    aVR_neg_img = Image.fromarray(cv2.flip(np.asarray(aVR_img),0)) # Vertical Flip\n    aVL_neg_img = Image.fromarray(cv2.flip(np.asarray(aVL_img),0)) # Vertical Flip\n    aVF_neg_img = Image.fromarray(cv2.flip(np.asarray(aVL_img),0)) # Vertical Flip\n    \n    \n    # Save 12 leads to respective folder\n    \n    I_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/I/')+ str(name)+str('.png'))\n    I_neg_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/I_Neg/')+ str(name)+str('.png'))\n    II_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/II/')+ str(name)+str('.png'))\n    II_neg_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/II_Neg/')+ str(name)+str('.png'))\n    III_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/III/')+ str(name)+str('.png'))\n    III_neg_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/III_Neg/')+ str(name)+str('.png'))\n    aVR_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/aVR/')+ str(name)+str('.png'))\n    aVR_neg_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/aVR_Neg/')+ str(name)+str('.png'))\n    aVL_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/aVL/')+ str(name)+str('.png'))\n    aVL_neg_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/aVL_Neg/')+ str(name)+str('.png'))\n    aVF_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/aVF/')+ str(name)+str('.png'))\n    aVF_neg_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/aVF_Neg/')+ str(name)+str('.png'))\n    V1_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/V1/')+ str(name)+str('.png'))\n    V2_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/V2/')+ str(name)+str('.png'))\n    V3_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/V3/')+ str(name)+str('.png'))\n    V4_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/V4/')+ str(name)+str('.png'))\n    V5_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/V5/')+ str(name)+str('.png'))\n    V6_img.save('/kaggle/working/ECG_leads/'+str(folder)+str('/V6/')+ str(name)+str('.png'))\n    \n    return I_img, I_neg_img, II_img, II_neg_img, III_img,III_neg_img,aVR_img,aVR_neg_img,aVL_img, aVL_neg_img, aVF_img, aVF_neg_img,V1_img,V2_img,V3_img,V4_img,V5_img,V6_img\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Applying the function to segment 12leads from the ECG Image and Save them to respective folder/subfolder.","metadata":{}},{"cell_type":"code","source":"%%time\n# MI 12_leads images\nfor i in range(0,MI_c_bg_df.shape[0]):\n    seg_save_12leads(image=MI_c_bg_df[\"PilImage\"][i],folder='MI', name= str(MI_c_bg_df[\"filename\"][i]))\n\n# Well Saved","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# MI 12_leads images\nfor i in range(0,HMI_c_bg_df.shape[0]):\n    seg_save_12leads(image=HMI_c_bg_df[\"PilImage\"][i],folder='HMI', name= str(HMI_c_bg_df[\"filename\"][i]))\n\n# Well Saved","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# MI 12_leads images\nfor i in range(0,AbnHB_c_bg_df.shape[0]):\n    seg_save_12leads(image=AbnHB_c_bg_df[\"PilImage\"][i],folder='AbnHB', name= str(AbnHB_c_bg_df[\"filename\"][i]))\n\n# Well Saved","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# MI 12_leads images\nfor i in range(0,Normal_c_bg_df.shape[0]):\n    seg_save_12leads(image=Normal_c_bg_df[\"PilImage\"][i],folder='Normal', name= str(Normal_c_bg_df[\"filename\"][i]))\n\n# Well Saved","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test the images were saved**","metadata":{}},{"cell_type":"code","source":"# to test the images were well saved...\nfnames = []\nfor path, dirs, files in os.walk(os.path.abspath(r\"./ECG_leads/AbnHB/I/\")):\n    for filename in fnmatch.filter(files, \"*.png\"):\n        print(filename)\n        fnames.append(filename)\nprint(len(fnames))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = plt.imread(r\"./ECG_leads/AbnHB/I/HB_31.png\")\nplt.imshow(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_neg = plt.imread(r\"./ECG_leads/AbnHB/I_Neg/HB_31.png\")\nplt.imshow(x_neg)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The 12 Leads were segmented to their respective folder & subfolders \n\n**Now time to train.**","metadata":{}},{"cell_type":"code","source":"def img_seg_12leads(image, width= 315, height= 315):\n    \"\"\" This function is used to crop the image and get 12 leads of  the ECG signals.\n      input: \n        image : the image cropped of ECG Signal\n        width = 315\n        height = 315\n\n        ######\n        # choices from paper & repo : https://github.com/mkfzdmr/COVID-19-ECG-Classification\n        ######\n      output: \n        12 img_out: 12 leads ECG\n    \"\"\"\n\n    # With ECG 12leads order \n    I_img   = image.crop((120.5, 0.5, width + 120.5 , 0.5 + height)).convert('L') # Converting Images to Grayscale \n    II_img  = image.crop((120.5, 315.5, width + 120.5 , 315.5+ height)).convert('L')\n    III_img = image.crop((120.5, 630.5, width + 120.5 , 630.5+ height)).convert('L')\n    aVL_img = image.crop((672.5, 315.5, width + 672.5 , 315.5+ height)).convert('L')\n    aVR_img = image.crop((672.5, 0.5, width + 672.5 , 0.5 + height)).convert('L')\n    aVF_img = image.crop((672.5, 630.5, width + 672.5 , 630.5+ height)).convert('L')\n    V1_img  = image.crop((1133.5, 0.5, width + 1133.5 , 0.5+ height)).convert('L')\n    V2_img  = image.crop((1133.5, 315.5, width + 1133.5 , 315.5+ height)).convert('L')\n    V3_img  = image.crop((1133.5, 630.5, width + 1133.5 , 630.5+ height)).convert('L')\n    V4_img  = image.crop((1639.5, 0.5, width + 1639.5 , 0.5 + height)).convert('L')\n    V5_img  = image.crop((1639.5, 0.5, width + 1639.5 , 0.5+ height)).convert('L')\n    V6_img  = image.crop((1639.5, 630.5, width + 1639.5 , 630.5+ height)).convert('L')\n\n    plt.figure(figsize=(20,10))\n    plt.subplot(4,4,1)\n    plt.imshow(image)\n    plt.title(\"Original\")\n\n    plt.subplot(4,4,2)\n    plt.imshow(I_img)\n    plt.title(\"I Lead\")\n  \n    plt.subplot(4,4,3)\n    plt.imshow(II_img)\n    plt.title(\"II Lead\")\n\n    plt.subplot(4,4,4)\n    plt.imshow(III_img)\n    plt.title(\"III Lead\")\n\n    plt.subplot(4,4,5)\n    plt.imshow(V1_img)\n    plt.title(\"V1 Lead\")\n\n    plt.subplot(4,4,6)\n    plt.imshow(V2_img)\n    plt.title(\"V2 Lead\")\n\n    plt.subplot(4,4,7)\n    plt.imshow(V3_img)\n    plt.title(\"V3 Lead\")\n\n    plt.subplot(4,4,8)\n    plt.imshow(V4_img)\n    plt.title(\"V4 Lead\")\n\n    plt.subplot(4,4,9)\n    plt.imshow(V5_img)\n    plt.title(\"V5 Lead\")\n\n    plt.subplot(4,4,10)\n    plt.imshow(V6_img)\n    plt.title(\"V6 Lead\")\n\n    plt.subplot(4,4,11)\n    plt.imshow(aVR_img)\n    plt.title(\"aVR Lead\")\n\n    plt.subplot(4,4,12)\n    plt.imshow(aVL_img)\n    plt.title(\"aVL Lead\")\n\n    plt.subplot(4,4,13)\n    plt.imshow(aVF_img)\n    plt.title(\"aVF Lead\")\n\n    plt.show()\n\n    \n    \n    return I_img,II_img,III_img,aVR_img,aVL_img, aVF_img,V1_img,V2_img,V3_img,V4_img,V5_img,V6_img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#Example : \n#I_img,II_img,III_img,aVR_img,aVL_img, aVF_img,V1_img,V2_img,V3_img,V4_img,V5_img,V6_img = img_seg_12leads(img_res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 3:","metadata":{}},{"cell_type":"markdown","source":"* GLCM Functions\n\n","metadata":{}},{"cell_type":"code","source":"def fast_glcm(img, vmin=0, vmax=255, nbit=8, kernel_size=5):\n    mi, ma = vmin, vmax\n    ks = kernel_size\n    h,w = img.shape\n\n    # digitize\n    bins = np.linspace(mi, ma+1, nbit+1)\n    gl1 = np.digitize(img, bins) - 1\n    gl2 = np.append(gl1[:,1:], gl1[:,-1:], axis=1)\n\n    # make glcm\n    glcm = np.zeros((nbit, nbit, h, w), dtype=np.uint8)\n    for i in range(nbit):\n        for j in range(nbit):\n            mask = ((gl1==i) & (gl2==j))\n            glcm[i,j, mask] = 1\n\n    kernel = np.ones((ks, ks), dtype=np.uint8)\n    for i in range(nbit):\n        for j in range(nbit):\n            glcm[i,j] = cv2.filter2D(glcm[i,j], -1, kernel)\n\n    glcm = glcm.astype(np.float32)\n    return glcm\n\n\ndef fast_glcm_mean(img, vmin=0, vmax=255, nbit=8, ks=5):\n    '''\n    calc glcm mean\n    '''\n    h,w = img.shape\n    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n    mean = np.zeros((h,w), dtype=np.float32)\n    for i in range(nbit):\n        for j in range(nbit):\n            mean += glcm[i,j] * i / (nbit)**2\n\n    return mean\n\n\ndef fast_glcm_std(img, vmin=0, vmax=255, nbit=8, ks=5):\n    '''\n    calc glcm std\n    '''\n    h,w = img.shape\n    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n    mean = np.zeros((h,w), dtype=np.float32)\n    for i in range(nbit):\n        for j in range(nbit):\n            mean += glcm[i,j] * i / (nbit)**2\n\n    std2 = np.zeros((h,w), dtype=np.float32)\n    for i in range(nbit):\n        for j in range(nbit):\n            std2 += (glcm[i,j] * i - mean)**2\n\n    std = np.sqrt(std2)\n    return std\n\n\ndef fast_glcm_contrast(img, vmin=0, vmax=255, nbit=8, ks=5):\n    '''\n    calc glcm contrast\n    '''\n    h,w = img.shape\n    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n    cont = np.zeros((h,w), dtype=np.float32)\n    for i in range(nbit):\n        for j in range(nbit):\n            cont += glcm[i,j] * (i-j)**2\n\n    return cont\n\n\ndef fast_glcm_dissimilarity(img, vmin=0, vmax=255, nbit=8, ks=5):\n    '''\n    calc glcm dissimilarity\n    '''\n    h,w = img.shape\n    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n    diss = np.zeros((h,w), dtype=np.float32)\n    for i in range(nbit):\n        for j in range(nbit):\n            diss += glcm[i,j] * np.abs(i-j)\n\n    return diss\n\n\ndef fast_glcm_homogeneity(img, vmin=0, vmax=255, nbit=8, ks=5):\n    '''\n    calc glcm homogeneity\n    '''\n    h,w = img.shape\n    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n    homo = np.zeros((h,w), dtype=np.float32)\n    for i in range(nbit):\n        for j in range(nbit):\n            homo += glcm[i,j] / (1.+(i-j)**2)\n\n    return homo\n\n\ndef fast_glcm_ASM(img, vmin=0, vmax=255, nbit=8, ks=5):\n    '''\n    calc glcm asm, energy\n    '''\n    h,w = img.shape\n    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n    asm = np.zeros((h,w), dtype=np.float32)\n    for i in range(nbit):\n        for j in range(nbit):\n            asm  += glcm[i,j]**2\n\n    ene = np.sqrt(asm)\n    return asm, ene\n\n\ndef fast_glcm_max(img, vmin=0, vmax=255, nbit=8, ks=5):\n    '''\n    calc glcm max\n    '''\n    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n    max_  = np.max(glcm, axis=(0,1))\n    return max_\n\n\ndef fast_glcm_entropy(img, vmin=0, vmax=255, nbit=8, ks=5):\n    '''\n    calc glcm entropy\n    '''\n    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n    pnorm = glcm / np.sum(glcm, axis=(0,1)) + 1./ks**2\n    ent  = np.sum(-pnorm * np.log(pnorm), axis=(0,1))\n    return ent","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Conveting PIL.Image.Image to np Array.\n# reference : https://app.pluralsight.com/guides/importing-image-data-into-numpy-arrays\n#img = np.asarray(I_img)\n#print(type(img))\n#plt.imshow(img)\n#img.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"mean = fast_glcm_mean(img)\nstd = fast_glcm_std(img)\ncont = fast_glcm_contrast(img)\ndiss = fast_glcm_dissimilarity(img)\nhomo = fast_glcm_homogeneity(img)\nasm, ene = fast_glcm_ASM(img)\nma = fast_glcm_max(img)\nent = fast_glcm_entropy(img)\n\nplt.figure(figsize=(10,4.5))\nfs = 15\nplt.subplot(2,5,1)\nplt.tick_params(labelbottom=False, labelleft=False)\nplt.imshow(img)\nplt.title('I_lead original', fontsize=fs)\n\nplt.subplot(2,5,2)\nplt.tick_params(labelbottom=False, labelleft=False)\nplt.imshow(mean)\nplt.title('I_lead mean', fontsize=fs)\n\nplt.subplot(2,5,3)\nplt.tick_params(labelbottom=False, labelleft=False)\nplt.imshow(std)\nplt.title('I_lead std', fontsize=fs)\n\nplt.subplot(2,5,4)\nplt.tick_params(labelbottom=False, labelleft=False)\nplt.imshow(cont)\nplt.title('I_lead contrast', fontsize=fs)\n\nplt.subplot(2,5,5)\nplt.tick_params(labelbottom=False, labelleft=False)\nplt.imshow(diss)\nplt.title('I_lead dissimilarity', fontsize=fs)\n\nplt.subplot(2,5,6)\nplt.tick_params(labelbottom=False, labelleft=False)\nplt.imshow(homo)\nplt.title('I_lead homogeneity', fontsize=fs)\n\nplt.subplot(2,5,7)\nplt.tick_params(labelbottom=False, labelleft=False)\nplt.imshow(asm)\nplt.title('I_lead ASM', fontsize=fs)\n\nplt.subplot(2,5,8)\nplt.tick_params(labelbottom=False, labelleft=False)\nplt.imshow(ene)\nplt.title('I_lead energy', fontsize=fs)\n\nplt.subplot(2,5,9)\nplt.tick_params(labelbottom=False, labelleft=False)\nplt.imshow(ma)\nplt.title('I_lead max', fontsize=fs)\n\nplt.subplot(2,5,10)\nplt.tick_params(labelbottom=False, labelleft=False)\nplt.imshow(ent)\nplt.title('I_lead entropy', fontsize=fs)\n\nplt.tight_layout(pad=0.8)\nplt.savefig('I_lead_output.jpg')\nplt.show()","metadata":{}},{"cell_type":"markdown","source":"# Task 4: Modeling","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, load_model, Sequential\nimport numpy as np\nimport pandas as pd\nimport shutil\nimport time\nimport cv2 as cv2\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport os\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom PIL import Image\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom IPython.core.display import display, HTML\n# stop annoying tensorflow warning messages\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:45:36.733568Z","iopub.execute_input":"2021-08-10T17:45:36.733918Z","iopub.status.idle":"2021-08-10T17:45:36.741948Z","shell.execute_reply.started":"2021-08-10T17:45:36.733886Z","shell.execute_reply":"2021-08-10T17:45:36.741143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Function to show images","metadata":{}}]}