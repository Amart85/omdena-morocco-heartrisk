{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECG_HEAR_RISK_OMDENA_AB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHFOAnuchfy1"
      },
      "source": [
        "# ECG Image Dataset \n",
        "Here I load and read the data, then label each folder with its respective name:\n",
        "\n",
        "\n",
        "*   **MI**\n",
        "*   **HMI**\n",
        "*   **AbnHB**\n",
        "*   **Normal**\n",
        "\n",
        "## First Step Segmentation\n",
        "Moreover, I create a function to Crope the ECG Report and leave just the ECG Signal.\n",
        "\n",
        "Then I extract the 12leads from the ECG Signal.\n",
        "\n",
        "## Second Step GLCM \n",
        "\n",
        "* feature extraction with GLCM _Energy_\n",
        "\n",
        "## Third Step  Hexaxial Mapping \n",
        "\n",
        "* Not done yet..\n",
        "\n",
        "\n",
        "#### Ayoub Berdeddouch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swIhTYNMyWIo"
      },
      "source": [
        "# Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1uvFJZxyMhM"
      },
      "source": [
        "import os\n",
        "import os.path\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd                                     \n",
        "import numpy as np                                      \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import cv2            \n",
        "from PIL import Image\n",
        "import datetime as dt\n",
        "import tensorflow as tf                                 \n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split    \n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix, classification_report, recall_score, precision_score, f1_score, roc_auc_score, roc_curve\n",
        "\n",
        "#Tensorflow _ Keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "from tensorflow.keras import datasets, layers, models, losses, Model, optimizers\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAveragePooling2D, SpatialDropout2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "## VGG Architectures \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "\n",
        "# Model Visualizer\n",
        "#to  install it run \n",
        "#!pip install visualkeras\n",
        "#import visualkeras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU0yREIHyg-6"
      },
      "source": [
        "# Loading Data \n",
        "\n",
        "## First Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C0yVBPiyit1"
      },
      "source": [
        "!wget \"https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/gwbz3fsgp8-2.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9krWWgcE7hO"
      },
      "source": [
        "!unzip gwbz3fsgp8-2.zip\n",
        "# done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7Qz4XsPMlHO"
      },
      "source": [
        "## Loading & Reading Images of **MI** (=Myocardial Infarction) Patiens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7jlj3_rIL5T"
      },
      "source": [
        "# MI patients data\n",
        "ECG_MI_dir_ = Path('/content/ECG Images of Myocardial Infarction Patients (240x12=2880)')\n",
        "\n",
        "ECG_MI_filepaths = list(ECG_MI_dir_.glob(r'**/*.jpg'))\n",
        "# Mapping the labels\n",
        "MI_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], ECG_MI_filepaths))\n",
        "# Paths & labels femalee eyes\n",
        "ECG_MI_filepaths = pd.Series(ECG_MI_filepaths, name = 'File').astype(str)\n",
        "MI_labels = pd.Series(MI_labels, name='Label')\n",
        "\n",
        "# Concatenating...\n",
        "MI_df = pd.concat([ECG_MI_filepaths, MI_labels], axis=1)\n",
        "MI_df['Label'] = \"MI\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2PbB80gLoS3"
      },
      "source": [
        "# Image Example of MI\n",
        "figure = plt.figure(figsize=(20,10))\n",
        "x = plt.imread(MI_df[\"File\"][0])\n",
        "plt.imshow(x)\n",
        "plt.xlabel(x.shape)\n",
        "plt.title(MI_df[\"Label\"][10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbQNcwopMv22"
      },
      "source": [
        "## Loading & Reading Images of **HMI** (= History of Myocardial Infarction) Patiens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w4y5SjYMOdE"
      },
      "source": [
        "# HMI patients data\n",
        "ECG_HMI_dir_ = Path('/content/ECG Images of Patient that have History of MI (172x12=2064)')\n",
        "\n",
        "ECG_HMI_filepaths = list(ECG_HMI_dir_.glob(r'**/*.jpg'))\n",
        "# Mapping the labels\n",
        "HMI_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], ECG_HMI_filepaths))\n",
        "# Paths & labels femalee eyes\n",
        "ECG_HMI_filepaths = pd.Series(ECG_HMI_filepaths, name = 'File').astype(str)\n",
        "HMI_labels = pd.Series(HMI_labels, name='Label')\n",
        "\n",
        "# Concatenating...\n",
        "HMI_df = pd.concat([ECG_HMI_filepaths, HMI_labels], axis=1)\n",
        "HMI_df['Label'] = \"HMI\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dES7hQvxNE3t"
      },
      "source": [
        "# Image Example of MI\n",
        "figure = plt.figure(figsize=(20,10))\n",
        "x = plt.imread(HMI_df[\"File\"][0])\n",
        "plt.imshow(x)\n",
        "plt.xlabel(x.shape)\n",
        "plt.title(HMI_df[\"Label\"][10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYFH01tRNI-p"
      },
      "source": [
        "## Loading & Reading Images of **AbnHB** (= Abnormal Heartbeat) Patiens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbpDR099NKRh"
      },
      "source": [
        "# AbnHB patients data\n",
        "ECG_AbnHB_dir_ = Path('/content/ECG Images of Patient that have abnormal heartbeat (233x12=2796)')\n",
        "\n",
        "ECG_AbnHB_filepaths = list(ECG_HMI_dir_.glob(r'**/*.jpg'))\n",
        "# Mapping the labels\n",
        "AbnHB_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], ECG_AbnHB_filepaths))\n",
        "# Paths & labels femalee eyes\n",
        "ECG_AbnHB_filepaths = pd.Series(ECG_AbnHB_filepaths, name = 'File').astype(str)\n",
        "AbnHB_labels = pd.Series(AbnHB_labels, name='Label')\n",
        "\n",
        "# Concatenating...\n",
        "AbnHB_df = pd.concat([ECG_AbnHB_filepaths, AbnHB_labels], axis=1)\n",
        "AbnHB_df['Label'] = \"ABNORMAL\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApiExE-KNqG4"
      },
      "source": [
        "# Image Example of MI\n",
        "figure = plt.figure(figsize=(20,10))\n",
        "x = plt.imread(AbnHB_df[\"File\"][0])\n",
        "plt.imshow(x)\n",
        "plt.xlabel(x.shape)\n",
        "plt.title(AbnHB_df[\"Label\"][10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq9kTnVMN_T0"
      },
      "source": [
        "## Loading & Reading Images of **NORMAL** (= NORMAL Heartbeat) Patiens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmRFepPPN_ym"
      },
      "source": [
        "# Normal patients data\n",
        "ECG_Normal_dir_ = Path('/content/Normal Person ECG Images (284x12=3408)')\n",
        "\n",
        "ECG_Normal_filepaths = list(ECG_Normal_dir_.glob(r'**/*.jpg'))\n",
        "# Mapping the labels\n",
        "Normal_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], ECG_Normal_filepaths))\n",
        "# Paths & labels femalee eyes\n",
        "ECG_Normal_filepaths = pd.Series(ECG_Normal_filepaths, name = 'File').astype(str)\n",
        "Normal_labels = pd.Series(Normal_labels, name='Label')\n",
        "\n",
        "# Concatenating...\n",
        "Normal_df = pd.concat([ECG_Normal_filepaths, Normal_labels], axis=1)\n",
        "Normal_df['Label'] = \"NORMAL\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTF9vdgDOcG9"
      },
      "source": [
        "# Image Example of MI\n",
        "figure = plt.figure(figsize=(20,10))\n",
        "x = plt.imread(Normal_df[\"File\"][0])\n",
        "plt.imshow(x)\n",
        "plt.xlabel(x.shape)\n",
        "plt.title(Normal_df[\"Label\"][10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBCudjVvP8zQ"
      },
      "source": [
        "### Then We concatenate our Dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd3H7iSQP_c_"
      },
      "source": [
        "# concat\n",
        "df_ECG = pd.concat([MI_df, HMI_df, AbnHB_df,Normal_df],ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3avCiJdiI_Gt"
      },
      "source": [
        "## Cropping the ECG images\n",
        "**img_crop** function below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5vJHWpmI-WH"
      },
      "source": [
        "#from PIL import Image\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "def im_crop(image,left=71.5, top= 287.5, right=2102, bottom= 1228):\n",
        "  \"\"\" This function is used to crop the image and get just the ECG signals.\n",
        "      input: \n",
        "        image : the image (jpg,png,...Etc)\n",
        "        left: location in left of image\n",
        "        top: location in top of image\n",
        "        right: location in right of image\n",
        "        bottom: location in bottom of image\n",
        "\n",
        "        ######\n",
        "        # choices from paper: left=71.5, top= 287.5, right=2102, bottom= 1228\n",
        "        ######\n",
        "      output: \n",
        "        img_out: the cropped image.\n",
        "  \"\"\"\n",
        "  img = Image.open(image) # for example : MI_df[\"File\"][0]\n",
        "  img_out = img.crop((left, top, right, bottom))\n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.subplot(121)\n",
        "  plt.imshow(img)\n",
        "  plt.title(\"Original\")\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.imshow(img_out)\n",
        "  plt.title(\"Cropped MI_df[\\\"File\\\"][0] \")\n",
        "  plt.show()\n",
        "\n",
        "  return img_out\n",
        "\n",
        "\n",
        "# Test \n",
        "img_cc = im_crop(MI_df[\"File\"][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYCo_uPEJcbI"
      },
      "source": [
        "## Now below to Crop the 12 leads from the ECG Signal Image Cropped"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMvxWMkEKUSd"
      },
      "source": [
        "#from PIL import Image\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "def im_crop_12leads(image, x, y,title, width= 315, height= 315):\n",
        "  \"\"\" This function is used to crop the image and get 12 leads of  the ECG signals.\n",
        "      input: \n",
        "        image : the image cropped of ECG Signal\n",
        "        left: location in left of image\n",
        "        top: location in top of image\n",
        "        right: location in right of image\n",
        "        bottom: location in bottom of image\n",
        "\n",
        "        ######\n",
        "        # choices from paper: left=71.5, top= 287.5, right=2102, bottom= 1228\n",
        "        ######\n",
        "      output: \n",
        "        img_out: the cropped image.\n",
        "  \"\"\"\n",
        "  img_out = image.crop((x, y, width + x , y+ height)).convert('L') # Converting Images to Grayscale\n",
        "  print(type(img_out))\n",
        "\n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.subplot(121)\n",
        "  plt.imshow(image)\n",
        "  plt.title(\"Original\")\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.imshow(img_out)\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "  return img_out\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZcHV6-TKA84"
      },
      "source": [
        "I_img = im_crop_12leads(img_cc,120.5,0.5,\"I Lead\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrg2UuE2erqC"
      },
      "source": [
        "II_img  = im_crop_12leads(img_cc,120.5,315.5,'II Lead') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qle6FEiEe4tN"
      },
      "source": [
        "III_img = im_crop_12leads(img_cc,120.5,630.5,'III Lead');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEkW4VF_MBWA"
      },
      "source": [
        "V1_img = im_crop_12leads(img_cc,1133.5,0.5,'V1 Lead')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N7NDqajeuZf"
      },
      "source": [
        "V2_img = im_crop_12leads(img_cc,1133.5,315.5,'V2 Lead');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFJz9gKxe_E2"
      },
      "source": [
        "V3_img  = im_crop_12leads(img_cc,1133.5,630.5,'V3 Lead');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69hakvdsUT57"
      },
      "source": [
        "V4_img = im_crop_12leads(img_cc,1639.5,0.5,'V4 Lead')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s5mc1Z6euQ8"
      },
      "source": [
        "V5_img = im_crop_12leads(img_cc,1639.5,315.5,'V5 Lead');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H6wJRJWVXkt"
      },
      "source": [
        "V6_img  = im_crop_12leads(img_cc,1639.5,630.5,'V6 Lead');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzRZRgNFeufl"
      },
      "source": [
        "aVL_img = im_crop_12leads(img_cc,672.5,315.5,'aVL Lead')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ31b0UtXEYg"
      },
      "source": [
        "aVR_img = im_crop_12leads(img_cc,672.5,0.5,'aVR Lead')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0iq1cHye7P1"
      },
      "source": [
        "aVF_img = im_crop_12leads(img_cc,672.5,630.5,'aVF Lead');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkuR2JAPfsks"
      },
      "source": [
        "## Below the Function to get All the 12 Leads at once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1bmuZIvcqxQ"
      },
      "source": [
        "#from PIL import Image\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "def im_crop_12leads(image, width= 315, height= 315):\n",
        "  \"\"\" This function is used to crop the image and get 12 leads of  the ECG signals.\n",
        "      input: \n",
        "        image : the image cropped of ECG Signal\n",
        "        width = 315\n",
        "        height = 315\n",
        "\n",
        "        ######\n",
        "        # choices from paper: left=71.5, top= 287.5, right=2102, bottom= 1228\n",
        "        ######\n",
        "      output: \n",
        "        12 img_out: 12 leads ECG\n",
        "  \"\"\"\n",
        "\n",
        "  \n",
        "  I_img   = image.crop((120.5, 0.5, width + 120.5 , 0.5 + height)).convert('L') # Converting Images to Grayscale \n",
        "  aVR_img = image.crop((672.5, 0.5, width + 672.5 , 0.5 + height)).convert('L')\n",
        "  V1_img  = image.crop(((1133.5, 0.5, width + (1133.5 , 0.5+ height)).convert('L')\n",
        "  V4_img  = image.crop((1639.5, 0.5, width + 1639.5 , 0.5 + height)).convert('L')\n",
        "  II_img  = image.crop((120.5, 315.5, width + 120.5 , 315.5+ height)).convert('L')\n",
        "  aVL_img = image.crop((672.5, 315.5, width + 672.5 , 315.5+ height)).convert('L')\n",
        "  V2_img  = image.crop((1133.5, 315.5, width + 1133.5 , 315.5+ height)).convert('L')\n",
        "  V5_img  = image.crop((1639.5, 0.5, width + 1639.5 , 0.5+ height)).convert('L')\n",
        "  III_img = image.crop((120.5, 630.5, width + 120.5 , 630.5+ height)).convert('L')\n",
        "  aVF_img = image.crop((672.5, 630.5, width + 672.5 , 630.5+ height)).convert('L')\n",
        "  V3_img  = image.crop((1133.5, 630.5, width + 1133.5 , 630.5+ height)).convert('L')\n",
        "  V6_img  = image.crop((1639.5, 630.5, width + 1639.5 , 630.5+ height)).convert('L')\n",
        "    \n",
        "    \n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.subplot(411)\n",
        "  plt.imshow(image)\n",
        "  plt.title(\"Original\")\n",
        "\n",
        "  plt.subplot(412)\n",
        "  plt.imshow(I_img)\n",
        "  plt.title(\"I Lead\")\n",
        "  \n",
        "  plt.subplot(413)\n",
        "  plt.imshow(II_img)\n",
        "  plt.title(\"II Lead\")\n",
        "\n",
        "  plt.subplot(414)\n",
        "  plt.imshow(III_img)\n",
        "  plt.title(\"III Lead\")\n",
        "\n",
        "  plt.subplot(421)\n",
        "  plt.imshow(V1_img)\n",
        "  plt.title(\"V1 Lead\")\n",
        "\n",
        "  plt.subplot(422)\n",
        "  plt.imshow(V2_img)\n",
        "  plt.title(\"V2 Lead\")\n",
        "\n",
        "  plt.subplot(423)\n",
        "  plt.imshow(V3_img)\n",
        "  plt.title(\"V3 Lead\")\n",
        "\n",
        "  plt.subplot(424)\n",
        "  plt.imshow(V4_img)\n",
        "  plt.title(\"V4 Lead\")\n",
        "\n",
        "  plt.subplot(431)\n",
        "  plt.imshow(V5_img)\n",
        "  plt.title(\"V5 Lead\")\n",
        "\n",
        "  plt.subplot(432)\n",
        "  plt.imshow(V6_img)\n",
        "  plt.title(\"V6 Lead\")\n",
        "\n",
        "  plt.subplot(433)\n",
        "  plt.imshow(aVR_img)\n",
        "  plt.title(\"aVR Lead\")\n",
        "\n",
        "  plt.subplot(434)\n",
        "  plt.imshow(aVL_img)\n",
        "  plt.title(\"aVL Lead\")\n",
        "\n",
        "  plt.subplot(441)\n",
        "  plt.imshow(aVF_img)\n",
        "  plt.title(\"aVF Lead\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  return I_img,II_img,III_img,V1_img,V2_img,V3_img,V4_img,V5_img,V6_img, aVR_img,aVL_img, aVF_img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUuvUW_JTx0o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgfdxJn9TyU3"
      },
      "source": [
        "# GLCM \n",
        "\n",
        "## Calculate properties of **G**ray-**l**evel **C**o-occurrence **M**atrix\n",
        "\n",
        "* Extracting Energy Features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmZhu8vdTzpK"
      },
      "source": [
        "def fast_glcm(img, vmin=0, vmax=255, nbit=8, kernel_size=5):\n",
        "    mi, ma = vmin, vmax\n",
        "    ks = kernel_size\n",
        "    h,w = img.shape\n",
        "\n",
        "    # digitize\n",
        "    bins = np.linspace(mi, ma+1, nbit+1)\n",
        "    gl1 = np.digitize(img, bins) - 1\n",
        "    gl2 = np.append(gl1[:,1:], gl1[:,-1:], axis=1)\n",
        "\n",
        "    # make glcm\n",
        "    glcm = np.zeros((nbit, nbit, h, w), dtype=np.uint8)\n",
        "    for i in range(nbit):\n",
        "        for j in range(nbit):\n",
        "            mask = ((gl1==i) & (gl2==j))\n",
        "            glcm[i,j, mask] = 1\n",
        "\n",
        "    kernel = np.ones((ks, ks), dtype=np.uint8)\n",
        "    for i in range(nbit):\n",
        "        for j in range(nbit):\n",
        "            glcm[i,j] = cv2.filter2D(glcm[i,j], -1, kernel)\n",
        "\n",
        "    glcm = glcm.astype(np.float32)\n",
        "    return glcm\n",
        "\n",
        "\n",
        "def fast_glcm_mean(img, vmin=0, vmax=255, nbit=8, ks=5):\n",
        "    '''\n",
        "    calc glcm mean\n",
        "    '''\n",
        "    h,w = img.shape\n",
        "    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n",
        "    mean = np.zeros((h,w), dtype=np.float32)\n",
        "    for i in range(nbit):\n",
        "        for j in range(nbit):\n",
        "            mean += glcm[i,j] * i / (nbit)**2\n",
        "\n",
        "    return mean\n",
        "\n",
        "\n",
        "def fast_glcm_std(img, vmin=0, vmax=255, nbit=8, ks=5):\n",
        "    '''\n",
        "    calc glcm std\n",
        "    '''\n",
        "    h,w = img.shape\n",
        "    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n",
        "    mean = np.zeros((h,w), dtype=np.float32)\n",
        "    for i in range(nbit):\n",
        "        for j in range(nbit):\n",
        "            mean += glcm[i,j] * i / (nbit)**2\n",
        "\n",
        "    std2 = np.zeros((h,w), dtype=np.float32)\n",
        "    for i in range(nbit):\n",
        "        for j in range(nbit):\n",
        "            std2 += (glcm[i,j] * i - mean)**2\n",
        "\n",
        "    std = np.sqrt(std2)\n",
        "    return std\n",
        "\n",
        "\n",
        "def fast_glcm_contrast(img, vmin=0, vmax=255, nbit=8, ks=5):\n",
        "    '''\n",
        "    calc glcm contrast\n",
        "    '''\n",
        "    h,w = img.shape\n",
        "    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n",
        "    cont = np.zeros((h,w), dtype=np.float32)\n",
        "    for i in range(nbit):\n",
        "        for j in range(nbit):\n",
        "            cont += glcm[i,j] * (i-j)**2\n",
        "\n",
        "    return cont\n",
        "\n",
        "\n",
        "def fast_glcm_dissimilarity(img, vmin=0, vmax=255, nbit=8, ks=5):\n",
        "    '''\n",
        "    calc glcm dissimilarity\n",
        "    '''\n",
        "    h,w = img.shape\n",
        "    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n",
        "    diss = np.zeros((h,w), dtype=np.float32)\n",
        "    for i in range(nbit):\n",
        "        for j in range(nbit):\n",
        "            diss += glcm[i,j] * np.abs(i-j)\n",
        "\n",
        "    return diss\n",
        "\n",
        "\n",
        "def fast_glcm_homogeneity(img, vmin=0, vmax=255, nbit=8, ks=5):\n",
        "    '''\n",
        "    calc glcm homogeneity\n",
        "    '''\n",
        "    h,w = img.shape\n",
        "    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n",
        "    homo = np.zeros((h,w), dtype=np.float32)\n",
        "    for i in range(nbit):\n",
        "        for j in range(nbit):\n",
        "            homo += glcm[i,j] / (1.+(i-j)**2)\n",
        "\n",
        "    return homo\n",
        "\n",
        "\n",
        "def fast_glcm_ASM(img, vmin=0, vmax=255, nbit=8, ks=5):\n",
        "    '''\n",
        "    calc glcm asm, energy\n",
        "    '''\n",
        "    h,w = img.shape\n",
        "    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n",
        "    asm = np.zeros((h,w), dtype=np.float32)\n",
        "    for i in range(nbit):\n",
        "        for j in range(nbit):\n",
        "            asm  += glcm[i,j]**2\n",
        "\n",
        "    ene = np.sqrt(asm)\n",
        "    return asm, ene\n",
        "\n",
        "\n",
        "def fast_glcm_max(img, vmin=0, vmax=255, nbit=8, ks=5):\n",
        "    '''\n",
        "    calc glcm max\n",
        "    '''\n",
        "    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n",
        "    max_  = np.max(glcm, axis=(0,1))\n",
        "    return max_\n",
        "\n",
        "\n",
        "def fast_glcm_entropy(img, vmin=0, vmax=255, nbit=8, ks=5):\n",
        "    '''\n",
        "    calc glcm entropy\n",
        "    '''\n",
        "    glcm = fast_glcm(img, vmin, vmax, nbit, ks)\n",
        "    pnorm = glcm / np.sum(glcm, axis=(0,1)) + 1./ks**2\n",
        "    ent  = np.sum(-pnorm * np.log(pnorm), axis=(0,1))\n",
        "    return ent\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7-CXR0CT5UV"
      },
      "source": [
        "# Conveting PIL.Image.Image to np Array.\n",
        "# reference : https://app.pluralsight.com/guides/importing-image-data-into-numpy-arrays\n",
        "img = np.asarray(I_img)\n",
        "print(type(img))\n",
        "plt.imshow(img)\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBj7scUlT90G"
      },
      "source": [
        "mean = fast_glcm_mean(img)\n",
        "std = fast_glcm_std(img)\n",
        "cont = fast_glcm_contrast(img)\n",
        "diss = fast_glcm_dissimilarity(img)\n",
        "homo = fast_glcm_homogeneity(img)\n",
        "asm, ene = fast_glcm_ASM(img)\n",
        "ma = fast_glcm_max(img)\n",
        "ent = fast_glcm_entropy(img)\n",
        "\n",
        "plt.figure(figsize=(10,4.5))\n",
        "fs = 15\n",
        "plt.subplot(2,5,1)\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "plt.imshow(img)\n",
        "plt.title('I_lead original', fontsize=fs)\n",
        "\n",
        "plt.subplot(2,5,2)\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "plt.imshow(mean)\n",
        "plt.title('I_lead mean', fontsize=fs)\n",
        "\n",
        "plt.subplot(2,5,3)\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "plt.imshow(std)\n",
        "plt.title('I_lead std', fontsize=fs)\n",
        "\n",
        "plt.subplot(2,5,4)\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "plt.imshow(cont)\n",
        "plt.title('I_lead contrast', fontsize=fs)\n",
        "\n",
        "plt.subplot(2,5,5)\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "plt.imshow(diss)\n",
        "plt.title('I_lead dissimilarity', fontsize=fs)\n",
        "\n",
        "plt.subplot(2,5,6)\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "plt.imshow(homo)\n",
        "plt.title('I_lead homogeneity', fontsize=fs)\n",
        "\n",
        "plt.subplot(2,5,7)\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "plt.imshow(asm)\n",
        "plt.title('I_lead ASM', fontsize=fs)\n",
        "\n",
        "plt.subplot(2,5,8)\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "plt.imshow(ene)\n",
        "plt.title('I_lead energy', fontsize=fs)\n",
        "\n",
        "plt.subplot(2,5,9)\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "plt.imshow(ma)\n",
        "plt.title('I_lead max', fontsize=fs)\n",
        "\n",
        "plt.subplot(2,5,10)\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "plt.imshow(ent)\n",
        "plt.title('I_lead entropy', fontsize=fs)\n",
        "\n",
        "plt.tight_layout(pad=0.8)\n",
        "plt.savefig('I_lead_output.jpg')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPmQbShWWyEG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw5avTPGbZh0"
      },
      "source": [
        "# Hexaxial Mapping "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq9BOF_ubbv9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}